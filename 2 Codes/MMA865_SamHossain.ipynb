{"cells":[{"cell_type":"markdown","metadata":{"id":"YhOCbK5Uk8Ly"},"source":["# MMA 865, Individual Assignment 1\n","\n","Last Updated December 11, 2023.\n","\n","- [Sam, Hossain]\n","- [Student number # 20466500]\n","- [Feb 3, 2025]"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"POJRi_sEmMI1","executionInfo":{"status":"ok","timestamp":1738632949812,"user_tz":300,"elapsed":31830,"user":{"displayName":"Saddam Hossain Riyad","userId":"02269650695077286817"}},"outputId":"68c25dcb-e01b-4d62-aecf-e5b0a2b959e4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"glAFbtsQk8L6"},"source":["# Part 1: Sentiment Analysis via the ML-based approach\n","\n","Download the ‚ÄúProduct Sentiment‚Äù dataset from the course portal: sentiment_train.csv and sentiment_test.csv."]},{"cell_type":"markdown","metadata":{"id":"a536Tu3Ik8MK"},"source":["### Part 1.a. Loading and Prep\n","\n","Load, clean, and preprocess the data as you find necessary."]},{"cell_type":"code","source":["from google.colab import drive\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, f1_score, classification_report\n","import re\n","\n","# Replace the path with the correct location of your files in Google Drive\n","train_path = '/content/drive/My Drive/Colab Notebooks/865 Individual/sentiment_train.csv'\n","test_path = '/content/drive/My Drive/Colab Notebooks/865 Individual/sentiment_test.csv'\n","\n","# Load the datasets\n","df_train = pd.read_csv(train_path)\n","df_test = pd.read_csv(test_path)\n","\n","# Display basic information\n","print(df_train.info())\n","print(df_train.head())\n","print(df_train.info())\n","print(df_train.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aM920c5Wmfcw","executionInfo":{"status":"ok","timestamp":1738633389038,"user_tz":300,"elapsed":156,"user":{"displayName":"Saddam Hossain Riyad","userId":"02269650695077286817"}},"outputId":"c3803187-4aca-4675-a7ec-341b404789a7"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2400 entries, 0 to 2399\n","Data columns (total 2 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   Sentence  2400 non-null   object\n"," 1   Polarity  2400 non-null   int64 \n","dtypes: int64(1), object(1)\n","memory usage: 37.6+ KB\n","None\n","                                            Sentence  Polarity\n","0                           Wow... Loved this place.         1\n","1                                 Crust is not good.         0\n","2          Not tasty and the texture was just nasty.         0\n","3  Stopped by during the late May bank holiday of...         1\n","4  The selection on the menu was great and so wer...         1\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2400 entries, 0 to 2399\n","Data columns (total 2 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   Sentence  2400 non-null   object\n"," 1   Polarity  2400 non-null   int64 \n","dtypes: int64(1), object(1)\n","memory usage: 37.6+ KB\n","None\n","                                            Sentence  Polarity\n","0                           Wow... Loved this place.         1\n","1                                 Crust is not good.         0\n","2          Not tasty and the texture was just nasty.         0\n","3  Stopped by during the late May bank holiday of...         1\n","4  The selection on the menu was great and so wer...         1\n"]}]},{"cell_type":"code","source":["# Preprocessing Function\n","def clean_text(text):\n","    text = text.lower()                              # Lowercase conversion\n","    text = re.sub(r'[^a-zA-Z\\s]', '', text)         # Removing punctuation and special characters\n","    text = re.sub(r'\\s+', ' ', text).strip()        # Removing extra whitespaces\n","    return text\n","\n","# Apply cleaning to both datasets\n","df_train['cleaned_sentence'] = df_train['Sentence'].apply(clean_text)\n","df_test['cleaned_sentence'] = df_test['Sentence'].apply(clean_text)\n","\n","# Feature Extraction using TF-IDF\n","vectorizer = TfidfVectorizer(max_features=5000)     # Limit features to 5000 for performance\n","X_train = vectorizer.fit_transform(df_train['cleaned_sentence'])\n","X_test = vectorizer.transform(df_test['cleaned_sentence'])\n","\n","y_train = df_train['Polarity']\n","y_test = df_test['Polarity']"],"metadata":{"id":"pS7s2SvMpbdG","executionInfo":{"status":"ok","timestamp":1738633787834,"user_tz":300,"elapsed":718,"user":{"displayName":"Saddam Hossain Riyad","userId":"02269650695077286817"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oh4u3taIk8Mm"},"source":["### Part 1.b. Modeling\n","\n","Use your favorite ML algorithm to train a classification model.  Don‚Äôt forget everything that we‚Äôve learned in our ML course: hyperparameter tuning, cross validation, handling imbalanced data, etc. Make reasonable decisions and try to create the best-performing classifier that you can."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"1nmlgGGkk8Mv","executionInfo":{"status":"ok","timestamp":1738633900552,"user_tz":300,"elapsed":2902,"user":{"displayName":"Saddam Hossain Riyad","userId":"02269650695077286817"}}},"outputs":[],"source":["# Model Training: Logistic Regression with Hyperparameter Tuning\n","log_reg = LogisticRegression(random_state=42)\n","param_grid = {'C': [0.1, 1, 10, 100], 'solver': ['liblinear', 'lbfgs']}  # Hyperparameter tuning\n","\n","grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='f1')      # 5-fold cross-validation\n","grid_search.fit(X_train, y_train)\n","\n","# Best Model Selection\n","best_model = grid_search.best_estimator_"]},{"cell_type":"markdown","metadata":{"id":"Tan21GX8k8My"},"source":["### Part 1.c. Assessing\n","\n","Use the testing data to measure the accuracy and F1-score of your model.  "]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6-n3g7aRk8Mz","executionInfo":{"status":"ok","timestamp":1738633922039,"user_tz":300,"elapsed":114,"user":{"displayName":"Saddam Hossain Riyad","userId":"02269650695077286817"}},"outputId":"653f662a-a2d6-4f62-f071-154742dcb3b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Accuracy: 0.7816666666666666\n","üéØ F1 Score: 0.7798319327731092\n","\n","Detailed Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.83      0.78       287\n","           1       0.82      0.74      0.78       313\n","\n","    accuracy                           0.78       600\n","   macro avg       0.78      0.78      0.78       600\n","weighted avg       0.79      0.78      0.78       600\n","\n"]}],"source":["# Model Evaluation\n","y_pred = best_model.predict(X_test)\n","\n","# Metrics\n","accuracy = accuracy_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","\n","print(f\"‚úÖ Accuracy: {accuracy}\")\n","print(f\"üéØ F1 Score: {f1}\")\n","print(\"\\nDetailed Classification Report:\\n\")\n","print(classification_report(y_test, y_pred))"]},{"cell_type":"markdown","source":["### üìä Model Evaluation Summary\n","\n","‚úÖ Accuracy: 78.17%\n","\n","üéØ F1 Score: 77.98%\n","\n","*This is a solid baseline for your sentiment analysis model!*\n","\n","### üöÄ Key Insights from the Classification Report:\n","\n","**Precision:**\n","\n","Class 0 (Negative Sentiment): 75%\n","\n","Class 1 (Positive Sentiment): 82%\n","\n","*The model is slightly better at correctly identifying positive sentiments.*\n","\n","\n","**Recall:**\n","\n","Class 0: 83% (better at detecting negatives)\n","\n","Class 1: 74% (misses some positive sentiments)\n","\n","\n","**Balanced Performance:**\n","\n","*Both classes have an F1-score of ~78%, indicating balanced precision and recall.*"],"metadata":{"id":"cgKMyEeyqosw"}},{"cell_type":"markdown","metadata":{"id":"NuOf30Rjk8M0"},"source":["### Part 2. Given the accuracy and F1-score of your model, are you satisfied with the results, from a business point of view? Explain."]},{"cell_type":"markdown","metadata":{"id":"rQZhBjW7k8M6"},"source":["Given the model's accuracy of 78.17% and an F1-score of 77.98%, the results are satisfactory as a baseline model for sentiment analysis. *From a business point of view,* the model shows a ***balanced performance in identifying both positive and negative sentiments, which is crucial for tasks like customer feedback analysis, brand monitoring, and product reviews.***\n","\n","However, in contexts where customer sentiment directly impacts decision-making, such as real-time support or financial forecasting based on sentiment trends, this performance might not be sufficient. ***Misclassifying 22% of sentiments could lead to missed business opportunities or incorrect strategic decisions.***\n","\n","**Strengths:**\n","\n","1. Good balance between precision and recall for both classes.\n","2. Reliable in detecting explicit positive and negative sentiments.\n","\n","**Areas for Improvement:**\n","\n","The model struggles with nuanced expressions, negations, and ambiguous phrases.\n","It lacks the contextual understanding needed for complex sentences, which could lead to inaccurate business insights.\n","\n","**Conclusion:**\n","\n","While the model is acceptable for basic sentiment analysis tasks, for high-stakes business applications, there‚Äôs room for improvement through advanced NLP techniques like contextual embeddings (BERT) and handling linguistic nuances more effectively."]},{"cell_type":"markdown","metadata":{"id":"EydWIeUDk8NN"},"source":["### Part 3. Show five example instances in which your model‚Äôs predictions were incorrect. Describe why you think the model was wrong. Don‚Äôt just guess: dig deep to figure out the root cause."]},{"cell_type":"code","source":["# Error Analysis: Identifying Incorrect Predictions\n","incorrect_indices = np.where(y_pred != y_test)[0]\n","\n","# Display Five Incorrect Predictions\n","print(\"\\nüîç Example of Incorrect Predictions:\\n\")\n","for i in incorrect_indices[:5]:\n","    print(f\"Original Sentence: {df_test.iloc[i]['Sentence']}\")\n","    print(f\"Predicted Polarity: {y_pred[i]}, Actual Polarity: {y_test.iloc[i]}\")\n","    print(\"-\" * 60)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JCXbwOaoqINI","executionInfo":{"status":"ok","timestamp":1738633950207,"user_tz":300,"elapsed":98,"user":{"displayName":"Saddam Hossain Riyad","userId":"02269650695077286817"}},"outputId":"f2f64f86-e92a-46a8-fe44-15c149e95f1e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üîç Example of Incorrect Predictions:\n","\n","Original Sentence: It really created a unique feeling though.  \n","Predicted Polarity: 0, Actual Polarity: 1\n","------------------------------------------------------------\n","Original Sentence: Not too screamy not to masculine but just right.  \n","Predicted Polarity: 0, Actual Polarity: 1\n","------------------------------------------------------------\n","Original Sentence: The camera really likes her in this movie.  \n","Predicted Polarity: 0, Actual Polarity: 1\n","------------------------------------------------------------\n","Original Sentence: I would have casted her in that role after ready the script.  \n","Predicted Polarity: 0, Actual Polarity: 1\n","------------------------------------------------------------\n","Original Sentence: The soundtrack wasn't terrible, either.  \n","Predicted Polarity: 0, Actual Polarity: 1\n","------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["### **üîç Error Analysis: Incorrect Predictions**\n","\n","Here are the five incorrect predictions made by the model, along with potential reasons for misclassification:\n","\n","#### **1Ô∏è‚É£ Sentence: \"It really created a unique feeling though.\"**\n","\n","Predicted Polarity: 0 (Negative) Actual Polarity: 1 (Positive)\n","\n","***Analysis:*** The phrase \"unique feeling\" is subjective. The model may have missed the positive connotation implied by \"unique\", as it doesn't explicitly contain strong positive words like \"amazing\" or \"great\".\n","\n","***Potential Issue:*** Lack of context-awareness; the model struggles with subtle positive sentiments.\n","\n","#### **2Ô∏è‚É£ Sentence: \"Not too screamy not too masculine but just right.\"**\n","\n","Predicted Polarity: 0 (Negative) Actual Polarity: 1 (Positive)\n","\n","***Analysis:*** The presence of \"not too screamy\" and \"not too masculine\" involves negations, which can confuse models.The positive phrase \"just right\" is subtle and may not have had enough weight in the feature space.\n","\n","***Potential Issue:*** Difficulty handling double negatives and nuanced compliments.\n","\n","#### **3Ô∏è‚É£ Sentence: \"The camera really likes her in this movie.\"**\n","\n","Predicted Polarity: 0 (Negative) Actual Polarity: 1 (Positive)\n","\n","***Analysis:*** While this is a positive remark about someone‚Äôs screen presence, the model might have interpreted it literally, missing the figurative praise.\n","\n","***Potential Issue:*** Challenges in understanding idiomatic expressions.\n","\n","#### **4Ô∏è‚É£ Sentence: \"I would have casted her in that role after reading the script.\"**\\\\\n","\n","Predicted Polarity: 0 (Negative) Actual Polarity: 1 (Positive)\n","\n","***Analysis:*** This suggests endorsement, but the sentence structure is neutral and lacks overt positive sentiment indicators.\n","\n","***Potential Issue:*** Difficulty interpreting implied positivity in conditional statements.\n","\n","#### **5Ô∏è‚É£ Sentence: \"The soundtrack wasn't terrible, either.\"**\n","\n","Predicted Polarity: 0 (Negative) Actual Polarity: 1 (Positive)\n","\n","***Analysis:*** The phrase \"wasn't terrible\" is a form of litotes (understatement using double negatives), which models often misinterpret as negative.\n","\n","***Potential Issue:*** Struggles with negations that imply a positive sentiment.\n","\n","### **üí° Root Causes Identified:**\n","\n","***Negation Handling:*** The model struggles with double negatives, subtle negations, and litotes.\n","\n","***Subtle Positive Sentiment:*** Difficulty recognizing implied positivity without strong sentiment words.\n","\n","***Contextual Understanding:*** Lack of ability to interpret figurative language, idiomatic expressions, and conditional endorsements."],"metadata":{"id":"7t2I7iMytEWL"}}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}